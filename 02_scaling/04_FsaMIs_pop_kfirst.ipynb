{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d0f0fce8-18cb-41da-9bf6-b12db9757b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "\n",
    "from libpysal.weights.util import full2W\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore')\n",
    "\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from joblib import Parallel, delayed   # <= add this\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from esda.moran import Moran"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bf321574-17e1-441a-9b57-73b83070ec58",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../00_data/13_final/cbsa_level.csv\")\n",
    "gdf = gpd.read_file(\"../00_data/01_raw/tl_2024_us_cbsa\", engine=\"pyogrio\")\n",
    "gdf['cbsacode'] = gdf['CBSAFP'].astype('float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "16c4fe7e-71ba-4c3c-8031-348095798206",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cbsa: 875\n"
     ]
    }
   ],
   "source": [
    "num_unique = df[\"cbsacode\"].nunique()\n",
    "print(\"cbsa:\", num_unique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5d25866e-b313-4225-8283-95c7894a35f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_ll = gdf.to_crs(\"EPSG:4326\").copy()\n",
    "gdf_ll[\"centroid\"] = gdf_ll.geometry.centroid  # may warn; matches old coordinates exactly\n",
    "gdf_ll[\"lon\"] = gdf_ll.centroid.x\n",
    "gdf_ll[\"lat\"] = gdf_ll.centroid.y\n",
    "gdf_ll[\"ALAND_acres\"] = gdf_ll[\"ALAND\"] / 4046.8564224\n",
    "df = df.merge(gdf_ll[['ALAND_acres','cbsacode','lon','lat']],how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "389b1a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import statsmodels.api as sm\n",
    "from numpy.linalg import eigh\n",
    "from esda.moran import Moran\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "# ---------------------------\n",
    "# Safe centroids (projected)\n",
    "# ---------------------------\n",
    "def add_lonlat_centroids(gdf, proj_crs=\"EPSG:5070\"):\n",
    "    \"\"\"\n",
    "    Compute centroids in a projected CRS, then bring them back to WGS84.\n",
    "    \"\"\"\n",
    "    gdf_proj = gdf.to_crs(proj_crs).copy()\n",
    "    cent_proj = gdf_proj.geometry.centroid  # planar centroid in meters\n",
    "    cent_wgs = gpd.GeoSeries(cent_proj, crs=proj_crs).to_crs(\"EPSG:4326\")\n",
    "    out = gdf.copy()\n",
    "    out[\"centroid\"] = cent_wgs\n",
    "    out[\"lon\"] = cent_wgs.x\n",
    "    out[\"lat\"] = cent_wgs.y\n",
    "    return out\n",
    "\n",
    "# ---------------------------------------\n",
    "# Fast kNN weights \n",
    "# ---------------------------------------\n",
    "\n",
    "def construct_knn_weights(coords, k):\n",
    "    # coords: (n,2) [lon, lat] in degrees\n",
    "    R = 6371.0\n",
    "    lon = np.radians(coords[:,0])[:,None]  # (n,1)\n",
    "    lat = np.radians(coords[:,1])[:,None]  # (n,1)\n",
    "\n",
    "    dlon = lon.T - lon                     # (n,n)\n",
    "    dlat = lat.T - lat                     # (n,n)\n",
    "\n",
    "    a = (np.sin(dlat/2.0)**2\n",
    "         + np.cos(lat) @ np.cos(lat).T * np.sin(dlon/2.0)**2)\n",
    "    c = 2.0 * np.arctan2(np.sqrt(a), np.sqrt(1.0 - a))\n",
    "    dist_mat = R * c\n",
    "    np.fill_diagonal(dist_mat, np.inf)     # exclude self exactly like before\n",
    "\n",
    "    n = dist_mat.shape[0]\n",
    "    W = np.zeros((n,n), dtype=float)\n",
    "    # identical neighbor selection and weights\n",
    "    for i in range(n):\n",
    "        row = dist_mat[i].copy()\n",
    "        knn_idx = np.argsort(row)[:k]      # same (default quicksort) behavior\n",
    "        thr = row[knn_idx[-1]]\n",
    "        if thr > 0:\n",
    "            W[i, knn_idx] = 1.0 - (dist_mat[i, knn_idx] / thr)\n",
    "\n",
    "    W_sym = (W + W.T) / 2.0\n",
    "    row_sums = W_sym.sum(axis=1, keepdims=True)\n",
    "    nz = row_sums[:,0] > 0\n",
    "    W_sym[nz] /= row_sums[nz]\n",
    "    return W_sym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dde41ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Robust Appendix-B forward selection ===\n",
    "def forward_select_esf(\n",
    "    eig_for_valid: np.ndarray,        # (n_valid, m_eigs)\n",
    "    ln_scal_vals: np.ndarray,      # (n_valid,)\n",
    "    ln_factor_vals: np.ndarray,       # (n_valid,)\n",
    "    W_lps_sub,                        # PySAL weights for valid rows (full2W)\n",
    "    alpha: float = 0.05,\n",
    "    permutations: int = 999,          # Moran permutations; keep 999 for parity\n",
    "    max_add: int = 100,\n",
    "    tol_delta_I: float = 1e-6,\n",
    "):\n",
    "    \"\"\"\n",
    "    Appendix B-style greedy forward selection minimizing Moran's I on residuals.\n",
    "    Guards against None/constant/NaN eigenvectors and singular fits.\n",
    "    Stops when p >= alpha, or Î”I is tiny, or max_add reached.\n",
    "    Returns: (best_model, best_resid, selected_idx)\n",
    "    \"\"\"\n",
    "    import numpy as np\n",
    "    import statsmodels.api as sm\n",
    "    from esda.moran import Moran\n",
    "\n",
    "    n_valid, m_eigs = eig_for_valid.shape\n",
    "    selected_idx = []\n",
    "\n",
    "    # Baseline\n",
    "    Xb = sm.add_constant(ln_scal_vals)\n",
    "    base = sm.OLS(ln_factor_vals, Xb).fit()\n",
    "    resid = base.resid\n",
    "    MI = Moran(resid, W_lps_sub, permutations=permutations)\n",
    "    if (MI.p_sim >= alpha) or (m_eigs == 0):\n",
    "        return base, resid, selected_idx\n",
    "\n",
    "    remaining = list(range(m_eigs))\n",
    "    best_model = base\n",
    "    best_resid = resid\n",
    "    last_I = MI.I\n",
    "\n",
    "    # Step 1\n",
    "    best = {\"I\": np.inf, \"p\": None, \"j\": None, \"model\": None, \"resid\": None}\n",
    "    for j in remaining:\n",
    "        xj = eig_for_valid[:, j]\n",
    "        if not np.all(np.isfinite(xj)) or np.nanstd(xj) == 0:\n",
    "            continue\n",
    "        X = sm.add_constant(np.column_stack([ln_scal_vals, xj]))\n",
    "        try:\n",
    "            m = sm.OLS(ln_factor_vals, X).fit()\n",
    "            r = m.resid\n",
    "            Mi = Moran(r, W_lps_sub, permutations=permutations)\n",
    "        except Exception:\n",
    "            continue\n",
    "        if (Mi.I < best[\"I\"]) or (np.isclose(Mi.I, best[\"I\"]) and (best[\"p\"] is None or Mi.p_sim > best[\"p\"])):\n",
    "            best.update({\"I\": Mi.I, \"p\": Mi.p_sim, \"j\": j, \"model\": m, \"resid\": r})\n",
    "\n",
    "    if best[\"j\"] is None:\n",
    "        return base, resid, selected_idx\n",
    "\n",
    "    selected_idx.append(best[\"j\"])\n",
    "    if best[\"j\"] in remaining:\n",
    "        remaining.remove(best[\"j\"])\n",
    "    best_model = best[\"model\"]\n",
    "    best_resid = best[\"resid\"]\n",
    "    if best[\"p\"] is not None and best[\"p\"] >= alpha:\n",
    "        return best_model, best_resid, selected_idx\n",
    "\n",
    "    # Step 2+\n",
    "    adds = 1\n",
    "    while remaining and adds < max_add:\n",
    "        cand = {\"I\": np.inf, \"p\": None, \"j\": None, \"model\": None, \"resid\": None}\n",
    "        for j in remaining:\n",
    "            X_eigs = eig_for_valid[:, selected_idx + [j]]\n",
    "            if not np.all(np.isfinite(X_eigs[:, -1])) or np.nanstd(X_eigs[:, -1]) == 0:\n",
    "                continue\n",
    "            X = sm.add_constant(np.column_stack([ln_scal_vals, X_eigs]))\n",
    "            try:\n",
    "                m = sm.OLS(ln_factor_vals, X).fit()\n",
    "                r = m.resid\n",
    "                Mi = Moran(r, W_lps_sub, permutations=permutations)\n",
    "            except Exception:\n",
    "                continue\n",
    "            if (Mi.I < cand[\"I\"]) or (np.isclose(Mi.I, cand[\"I\"]) and (cand[\"p\"] is None or Mi.p_sim > cand[\"p\"])):\n",
    "                cand.update({\"I\": Mi.I, \"p\": Mi.p_sim, \"j\": j, \"model\": m, \"resid\": r})\n",
    "\n",
    "        if cand[\"j\"] is None:\n",
    "            break\n",
    "\n",
    "        # early stop if I barely improves\n",
    "        if (last_I - cand[\"I\"]) < tol_delta_I:\n",
    "            break\n",
    "\n",
    "        selected_idx.append(cand[\"j\"])\n",
    "        if cand[\"j\"] in remaining:\n",
    "            remaining.remove(cand[\"j\"])\n",
    "        best_model = cand[\"model\"]\n",
    "        best_resid = cand[\"resid\"]\n",
    "        last_I = cand[\"I\"]\n",
    "        adds += 1\n",
    "        if cand[\"p\"] is not None and cand[\"p\"] >= alpha:\n",
    "            break\n",
    "\n",
    "    return best_model, best_resid, selected_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c6e11e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_FsAMIs(\n",
    "    df: pd.DataFrame,\n",
    "    factor_columns,\n",
    "    population_column: str,\n",
    "    cbsa_column: str = \"cbsacode\",\n",
    "    alpha: float = 0.05,\n",
    "    moran_permutations_search: int = 199,\n",
    "    moran_permutations_final: int = 999,\n",
    "    n_jobs: int = -1,\n",
    "    backend: str = \"loky\",\n",
    "    k_values = (4, 6, 8, 10, 12, 14, 15, 20, 25, 30),\n",
    "):\n",
    "    \"\"\"\n",
    "    Stage 1 (per k): choose the single ESF eigenvector that MINIMIZES Moran's I on residuals\n",
    "                     after adding it to ln(pop). Prefer models with p>=alpha; tie-break on |I| then AIC.\n",
    "                     The chosen eigenvector index is recorded as 'lead_eig_idx' for that k.\n",
    "    Stage 2 (at best_k): baseline -> if needed, run your forward selection (which also minimizes Moran's I).\n",
    "    Returns:\n",
    "      results_df : per-CBSA FsAMI and model stats at best_k\n",
    "      k_diag_df  : per-factor per-k diagnostics (lead_eig_idx, I, p, AIC, baseline I/p)\n",
    "    \"\"\"\n",
    "    n_all = len(df)\n",
    "    print(\"Merged data rows:\", n_all)\n",
    "    if n_all == 0:\n",
    "        return pd.DataFrame(), pd.DataFrame()\n",
    "\n",
    "    # --- numeric copy & coercion ---\n",
    "    df_num = df.copy()\n",
    "    for col in [population_column, *factor_columns, \"lon\", \"lat\"]:\n",
    "        if col in df_num.columns:\n",
    "            df_num[col] = pd.to_numeric(df_num[col], errors=\"coerce\")\n",
    "\n",
    "    coords_all = df_num[[\"lon\", \"lat\"]].to_numpy()\n",
    "\n",
    "    # Precompute W and eigenstuff for all k\n",
    "    k_cache = {}\n",
    "    H = np.eye(n_all) - np.ones((n_all, n_all)) / n_all\n",
    "    for k in k_values:\n",
    "        W_sym_k = construct_knn_weights(coords_all, k=k)\n",
    "        Omega = H @ W_sym_k @ H\n",
    "        evals, evecs = np.linalg.eigh(Omega)\n",
    "        pos = evals > 1e-12\n",
    "        evals_pos = evals[pos]\n",
    "        evecs_pos = evecs[:, pos]\n",
    "        order = np.argsort(evals_pos)[::-1]  # descending\n",
    "        k_cache[k] = {\n",
    "            \"W_sym\": W_sym_k,\n",
    "            \"evecs\": evecs_pos[:, order],\n",
    "            \"evals\": evals_pos[order],\n",
    "        }\n",
    "\n",
    "    ln_pop_all = np.log(df_num[population_column]).astype(float)\n",
    "\n",
    "    def _run_one_factor(factor: str):\n",
    "        rows = []\n",
    "        diag_rows = []\n",
    "\n",
    "        fac_vals = df_num[factor]\n",
    "        pop_vals = df_num[population_column]\n",
    "\n",
    "        coord_ok = (\n",
    "            df_num[\"lon\"].notna() & df_num[\"lat\"].notna() &\n",
    "            np.isfinite(df_num[\"lon\"].to_numpy()) &\n",
    "            np.isfinite(df_num[\"lat\"].to_numpy())\n",
    "        )\n",
    "        valid_mask = (\n",
    "            fac_vals.notna() & pop_vals.notna() &\n",
    "            (fac_vals > 0) & (pop_vals > 0) &\n",
    "            np.isfinite(fac_vals.to_numpy()) &\n",
    "            np.isfinite(pop_vals.to_numpy()) &\n",
    "            coord_ok\n",
    "        )\n",
    "        if not valid_mask.any():\n",
    "            print(f\"[Skip] No valid data for {factor}\")\n",
    "            return rows, diag_rows\n",
    "\n",
    "        idx_valid = np.where(valid_mask)[0]\n",
    "        ln_factor = np.log(fac_vals.loc[valid_mask].to_numpy())\n",
    "        ln_pop    = ln_pop_all[valid_mask.to_numpy()]\n",
    "        cbsa_vals = df_num.loc[valid_mask, cbsa_column].to_numpy()\n",
    "\n",
    "        # ----- Stage 1: for each k, pick the single eigenvector that minimizes Moran's I on residuals -----\n",
    "        per_k_choice = {}  # k -> dict with chosen eig stats\n",
    "        for k in k_values:\n",
    "            cache = k_cache[k]\n",
    "            W_sub = cache[\"W_sym\"][idx_valid][:, idx_valid]\n",
    "            W_lps_sub = full2W(W_sub); W_lps_sub.transform = 'r'\n",
    "\n",
    "            # Baseline (for diagnostics)\n",
    "            Xb = sm.add_constant(ln_pop)\n",
    "            model_b = sm.OLS(ln_factor, Xb).fit()\n",
    "            resid_b = model_b.resid\n",
    "            MI_b = Moran(resid_b, W_lps_sub, permutations=moran_permutations_search)\n",
    "            b_I, b_p = float(MI_b.I), float(MI_b.p_sim)\n",
    "\n",
    "            # Scan all eigenvectors: ln_factor ~ const + ln_pop + e_j\n",
    "            E = cache[\"evecs\"][idx_valid, :]\n",
    "            E = E - E.mean(axis=0, keepdims=True)  # column-center\n",
    "            best = None\n",
    "            for j in range(E.shape[1]):\n",
    "                Xj = np.column_stack([np.ones_like(ln_pop), ln_pop, E[:, j]])\n",
    "                mj = sm.OLS(ln_factor, Xj).fit()\n",
    "                rj = mj.resid\n",
    "                MI_j = Moran(rj, W_lps_sub, permutations=moran_permutations_search)\n",
    "                I_j, p_j = float(MI_j.I), float(MI_j.p_sim)\n",
    "                aic_j = float(mj.aic)\n",
    "\n",
    "                cand = {\n",
    "                    \"k\": int(k), \"eig_idx\": int(j),\n",
    "                    \"I\": I_j, \"p\": p_j, \"AIC\": aic_j,\n",
    "                    \"beta\": float(mj.params[1]),\n",
    "                    \"p_beta\": float(mj.pvalues[1]),\n",
    "                }\n",
    "                # Selection rule within k:\n",
    "                #   Prefer p>=alpha; among those, minimize |I|, then AIC.\n",
    "                #   If none reach p>=alpha, maximize p, then minimize |I|, then AIC.\n",
    "                if best is None:\n",
    "                    best = cand\n",
    "                else:\n",
    "                    def rank_key(d):\n",
    "                        feas = (d[\"p\"] >= alpha)\n",
    "                        # negative because we want feasible first (True>False)\n",
    "                        return (\n",
    "                            0 if feas else 1,          # feasible first\n",
    "                            abs(d[\"I\"]) if feas else -d[\"p\"],  # minimize |I| if feasible else maximize p\n",
    "                            d[\"AIC\"]                   # then AIC\n",
    "                        )\n",
    "                    if rank_key(cand) < rank_key(best):\n",
    "                        best = cand\n",
    "\n",
    "            # store winner for this k (and log baseline too)\n",
    "            best.update({\"baseline_I\": b_I, \"baseline_p\": b_p})\n",
    "            per_k_choice[k] = best\n",
    "            diag_rows.append({\n",
    "                \"factor\": factor,\n",
    "                \"k\": int(k),\n",
    "                \"lead_eig_idx\": int(best[\"eig_idx\"]),\n",
    "                \"lead_I\": float(best[\"I\"]),\n",
    "                \"lead_p\": float(best[\"p\"]),\n",
    "                \"aic_single\": float(best[\"AIC\"]),\n",
    "                \"baseline_I\": float(b_I),\n",
    "                \"baseline_p\": float(b_p),\n",
    "            })\n",
    "\n",
    "        # choose best_k across k:\n",
    "        #   Prefer p>=alpha; among those, minimize |I|, then AIC, then smaller k\n",
    "        def across_k_key(d):\n",
    "            feas = (d[\"p\"] >= alpha)\n",
    "            return (\n",
    "                0 if feas else 1,\n",
    "                abs(d[\"I\"]) if feas else -d[\"p\"],\n",
    "                d[\"AIC\"],\n",
    "                d[\"k\"],\n",
    "            )\n",
    "\n",
    "        best_k, best_choice = min(\n",
    "            ((k, info) for k, info in per_k_choice.items()),\n",
    "            key=lambda kv: across_k_key(kv[1])\n",
    "        )\n",
    "        best_k = int(best_k)\n",
    "\n",
    "        # ----- Stage 2 at best_k: baseline -> forward selection (your function) -----\n",
    "        cache = k_cache[best_k]\n",
    "        W_sub = cache[\"W_sym\"][idx_valid][:, idx_valid]\n",
    "        W_lps_sub = full2W(W_sub); W_lps_sub.transform = 'r'\n",
    "\n",
    "        # Baseline at best_k (for consistency)\n",
    "        Xb = sm.add_constant(ln_pop)\n",
    "        model_b = sm.OLS(ln_factor, Xb).fit()\n",
    "        resid_b = model_b.resid\n",
    "        MI_b = Moran(resid_b, W_lps_sub, permutations=moran_permutations_search)\n",
    "        b_I, b_p = float(MI_b.I), float(MI_b.p_sim)\n",
    "\n",
    "        best_model = model_b\n",
    "        best_resid = resid_b\n",
    "        selected_m = 0\n",
    "\n",
    "        if b_p < alpha:\n",
    "            eig_for_valid = cache[\"evecs\"][idx_valid, :]\n",
    "            eig_for_valid = eig_for_valid - eig_for_valid.mean(axis=0, keepdims=True)\n",
    "            # Your forward selection is assumed to minimize Moran's I and stop when p>=alpha\n",
    "            best_model, best_resid, sel_idx = forward_select_esf(\n",
    "                eig_for_valid=eig_for_valid,\n",
    "                ln_scal_vals=ln_pop,\n",
    "                ln_factor_vals=ln_factor,\n",
    "                W_lps_sub=W_lps_sub,\n",
    "                alpha=alpha,\n",
    "                permutations=moran_permutations_search\n",
    "            )\n",
    "            selected_m = len(sel_idx)\n",
    "\n",
    "        # Final Moran at best_k\n",
    "        MI_f = Moran(best_resid, W_lps_sub, permutations=moran_permutations_final)\n",
    "        f_I, f_p = float(MI_f.I), float(MI_f.p_sim)\n",
    "\n",
    "        # Extract stats\n",
    "        aic_final = float(best_model.aic)\n",
    "        beta = float(best_model.params[1])\n",
    "        pval = float(best_model.pvalues[1])\n",
    "        ci_low, ci_up = map(float, best_model.conf_int(alpha=0.05)[1])\n",
    "\n",
    "        for i_local, cval in enumerate(cbsa_vals):\n",
    "            rows.append({\n",
    "                cbsa_column: cval,\n",
    "                \"factor\": factor,\n",
    "                \"best_k\": int(best_k),\n",
    "                \"best_k_lead_eig_idx\": int(best_choice[\"eig_idx\"]),\n",
    "                \"baseline_moran_value\": float(b_I),\n",
    "                \"baseline_moran_p\": float(b_p),\n",
    "                \"final_moran_value\": float(f_I),\n",
    "                \"final_moran_p\": float(f_p),\n",
    "                \"selected_m_eigs\": int(selected_m),\n",
    "                \"FsAMI\": float(best_resid[i_local]),\n",
    "                \"beta\": beta,\n",
    "                \"p_value\": pval,\n",
    "                \"CI_lower\": ci_low,\n",
    "                \"CI_upper\": ci_up,\n",
    "                \"AIC\": aic_final\n",
    "            })\n",
    "        return rows, diag_rows\n",
    "\n",
    "    results_lists = Parallel(n_jobs=n_jobs, backend=backend, verbose=0)(\n",
    "        delayed(_run_one_factor)(factor) for factor in factor_columns\n",
    "    )\n",
    "\n",
    "    flat_rows, flat_diag = [], []\n",
    "    for res_rows, diag_rows in results_lists:\n",
    "        flat_rows.extend(res_rows or [])\n",
    "        flat_diag.extend(diag_rows or [])\n",
    "\n",
    "    results_df = pd.DataFrame(flat_rows)\n",
    "    k_diag_df  = pd.DataFrame(flat_diag).sort_values([\"factor\", \"k\"]).reset_index(drop=True)\n",
    "    return results_df, k_diag_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bdd207a8-cf3c-44da-b18c-7f78aa8ce3ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged data rows: 875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lidouhao/anaconda3/envs/capstone_depression/lib/python3.9/site-packages/libpysal/weights/weights.py:224: UserWarning: The weights matrix is not fully connected: \n",
      " There are 3 disconnected components.\n",
      " There are 2 islands with ids: 367, 773.\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('WARNING: ', 367, ' is an island (no neighbors)')\n",
      "('WARNING: ', 773, ' is an island (no neighbors)')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lidouhao/anaconda3/envs/capstone_depression/lib/python3.9/site-packages/libpysal/weights/weights.py:224: UserWarning: The weights matrix is not fully connected: \n",
      " There are 3 disconnected components.\n",
      " There are 2 islands with ids: 367, 773.\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('WARNING: ', 367, ' is an island (no neighbors)')\n",
      "('WARNING: ', 773, ' is an island (no neighbors)')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lidouhao/anaconda3/envs/capstone_depression/lib/python3.9/site-packages/libpysal/weights/weights.py:224: UserWarning: The weights matrix is not fully connected: \n",
      " There are 2 disconnected components.\n",
      "  warnings.warn(message)\n",
      "/Users/lidouhao/anaconda3/envs/capstone_depression/lib/python3.9/site-packages/libpysal/weights/weights.py:224: UserWarning: The weights matrix is not fully connected: \n",
      " There are 2 disconnected components.\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results (FsAMI):\n",
      "   cbsacode factor  best_k  best_k_lead_eig_idx  baseline_moran_value  \\\n",
      "0   10100.0  BINGE      20                    2              0.613429   \n",
      "1   10140.0  BINGE      20                    2              0.613429   \n",
      "2   10180.0  BINGE      20                    2              0.613429   \n",
      "3   10220.0  BINGE      20                    2              0.613429   \n",
      "4   10300.0  BINGE      20                    2              0.613429   \n",
      "5   10420.0  BINGE      20                    2              0.613429   \n",
      "6   10460.0  BINGE      20                    2              0.613429   \n",
      "7   10500.0  BINGE      20                    2              0.613429   \n",
      "8   10540.0  BINGE      20                    2              0.613429   \n",
      "9   10580.0  BINGE      20                    2              0.613429   \n",
      "\n",
      "   baseline_moran_p  final_moran_value  final_moran_p  selected_m_eigs  \\\n",
      "0             0.005           0.027524          0.018               33   \n",
      "1             0.005           0.027524          0.018               33   \n",
      "2             0.005           0.027524          0.018               33   \n",
      "3             0.005           0.027524          0.018               33   \n",
      "4             0.005           0.027524          0.018               33   \n",
      "5             0.005           0.027524          0.018               33   \n",
      "6             0.005           0.027524          0.018               33   \n",
      "7             0.005           0.027524          0.018               33   \n",
      "8             0.005           0.027524          0.018               33   \n",
      "9             0.005           0.027524          0.018               33   \n",
      "\n",
      "      FsAMI      beta  p_value  CI_lower  CI_upper          AIC  \n",
      "0 -0.067151  1.023701      0.0  1.019033  1.028369 -1817.172095  \n",
      "1  0.035240  1.023701      0.0  1.019033  1.028369 -1817.172095  \n",
      "2  0.026327  1.023701      0.0  1.019033  1.028369 -1817.172095  \n",
      "3 -0.029140  1.023701      0.0  1.019033  1.028369 -1817.172095  \n",
      "4 -0.021988  1.023701      0.0  1.019033  1.028369 -1817.172095  \n",
      "5 -0.061400  1.023701      0.0  1.019033  1.028369 -1817.172095  \n",
      "6  0.000736  1.023701      0.0  1.019033  1.028369 -1817.172095  \n",
      "7 -0.081531  1.023701      0.0  1.019033  1.028369 -1817.172095  \n",
      "8  0.007509  1.023701      0.0  1.019033  1.028369 -1817.172095  \n",
      "9  0.020753  1.023701      0.0  1.019033  1.028369 -1817.172095  \n",
      "\n",
      "Per-k diagnostics (chosen eigenvector, Moran's I, AIC):\n",
      "  factor   k  lead_eig_idx    lead_I  lead_p   aic_single  baseline_I  \\\n",
      "0  BINGE   4            20  0.689530   0.005  -954.310653    0.706379   \n",
      "1  BINGE   6            16  0.643436   0.005 -1015.785678    0.683203   \n",
      "2  BINGE   8             9  0.634881   0.005 -1005.878887    0.669671   \n",
      "3  BINGE  10             5  0.570451   0.005 -1117.109995    0.658037   \n",
      "4  BINGE  12             2  0.577731   0.005 -1078.782010    0.647656   \n",
      "5  BINGE  14             2  0.537481   0.005 -1139.327511    0.638248   \n",
      "6  BINGE  15             2  0.513692   0.005 -1170.580251    0.633291   \n",
      "7  BINGE  20             2  0.472010   0.005 -1204.666362    0.613429   \n",
      "8  BINGE  25             2  0.491131   0.005 -1123.910290    0.593149   \n",
      "9  BINGE  30             2  0.468754   0.005 -1125.792253    0.575437   \n",
      "\n",
      "   baseline_p  \n",
      "0       0.005  \n",
      "1       0.005  \n",
      "2       0.005  \n",
      "3       0.005  \n",
      "4       0.005  \n",
      "5       0.005  \n",
      "6       0.005  \n",
      "7       0.005  \n",
      "8       0.005  \n",
      "9       0.005  \n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    factor_columns = [\n",
    "        'BINGE','CSMOKING','DEPRESSION','DIABETES','LPA','OBESITY',\n",
    "        'adult_smoking','adult_obesity','excessive_drinking','diabetes_prevalence',\n",
    "        'some_college','unemployment','children_single_parent','mental_health_providers',\n",
    "        'median_household_income','driving_alone_to_work','sti','FFR20','gdp',\n",
    "        'coverage_50','coverage_60','coverage_70','coverage_80','coverage_90',\n",
    "        'noise50n','noise60n','noise70n','noise80n','noise90n','Park_Area_Acres'\n",
    "    ]\n",
    "\n",
    "    results_df, k_diag_df = calculate_FsAMIs(   # <= now returns two tables\n",
    "        df=df,\n",
    "        factor_columns=factor_columns,\n",
    "        population_column=\"TotalPopulation\",\n",
    "        cbsa_column=\"cbsacode\",\n",
    "        alpha=0.05,\n",
    "        n_jobs=-1,          # use all cores\n",
    "        backend=\"loky\",     # safe fork on most platforms\n",
    "    )\n",
    "\n",
    "    print(\"Results (FsAMI):\")\n",
    "    print(results_df.head(10))\n",
    "    print(\"\\nPer-k diagnostics (chosen eigenvector, Moran's I, AIC):\")\n",
    "    print(k_diag_df.head(10))\n",
    "\n",
    "    # optional: save\n",
    "    results_df.to_csv(\"../00_data/14_output/FsAMI_results_0924.csv\", index=False)\n",
    "    k_diag_df.to_csv(\"../00_data/14_output/FsAMI_k_diagnostics_0924.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "capstone_depression",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
