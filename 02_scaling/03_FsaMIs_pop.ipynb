{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d0f0fce8-18cb-41da-9bf6-b12db9757b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "\n",
    "from libpysal.weights.util import full2W\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore')\n",
    "\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "np.random.seed(42)\n",
    "import statsmodels.api as sm\n",
    "from numpy.linalg import eigh\n",
    "from esda.moran import Moran"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bf321574-17e1-441a-9b57-73b83070ec58",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../00_data/03_final/cbsa_level.csv\")\n",
    "gdf = gpd.read_file(\"../00_data/01_raw/tl_2024_us_cbsa\", engine=\"pyogrio\")\n",
    "gdf['cbsacode'] = gdf['CBSAFP'].astype('float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "16c4fe7e-71ba-4c3c-8031-348095798206",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cbsa: 875\n"
     ]
    }
   ],
   "source": [
    "num_unique = df[\"cbsacode\"].nunique()\n",
    "print(\"cbsa:\", num_unique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5d25866e-b313-4225-8283-95c7894a35f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_ll = gdf.to_crs(\"EPSG:4326\").copy()\n",
    "gdf_ll[\"centroid\"] = gdf_ll.geometry.centroid  # may warn; matches old coordinates exactly\n",
    "gdf_ll[\"lon\"] = gdf_ll.centroid.x\n",
    "gdf_ll[\"lat\"] = gdf_ll.centroid.y\n",
    "gdf_ll[\"ALAND_acres\"] = gdf_ll[\"ALAND\"] / 4046.8564224\n",
    "df = df.merge(gdf_ll[['ALAND_acres','cbsacode','lon','lat']],how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "389b1a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ---------------------------\n",
    "# centroids (projected)\n",
    "# ---------------------------\n",
    "def add_lonlat_centroids(gdf, proj_crs=\"EPSG:5070\"):\n",
    "    \"\"\"\n",
    "    Compute centroids in a projected CRS, then bring them back to WGS84.\n",
    "    \"\"\"\n",
    "    gdf_proj = gdf.to_crs(proj_crs).copy()\n",
    "    cent_proj = gdf_proj.geometry.centroid  # planar centroid in meters\n",
    "    cent_wgs = gpd.GeoSeries(cent_proj, crs=proj_crs).to_crs(\"EPSG:4326\")\n",
    "    out = gdf.copy()\n",
    "    out[\"centroid\"] = cent_wgs\n",
    "    out[\"lon\"] = cent_wgs.x\n",
    "    out[\"lat\"] = cent_wgs.y\n",
    "    return out\n",
    "\n",
    "# ---------------------------------------\n",
    "# Fast kNN weights \n",
    "# ---------------------------------------\n",
    "\n",
    "def construct_knn_weights(coords, k):\n",
    "    # coords: (n,2) [lon, lat] in degrees\n",
    "    R = 6371.0\n",
    "    lon = np.radians(coords[:,0])[:,None]  # (n,1)\n",
    "    lat = np.radians(coords[:,1])[:,None]  # (n,1)\n",
    "\n",
    "    dlon = lon.T - lon                     # (n,n)\n",
    "    dlat = lat.T - lat                     # (n,n)\n",
    "\n",
    "    a = (np.sin(dlat/2.0)**2\n",
    "         + np.cos(lat) @ np.cos(lat).T * np.sin(dlon/2.0)**2)\n",
    "    c = 2.0 * np.arctan2(np.sqrt(a), np.sqrt(1.0 - a))\n",
    "    dist_mat = R * c\n",
    "    np.fill_diagonal(dist_mat, np.inf)     # exclude self exactly like before\n",
    "\n",
    "    n = dist_mat.shape[0]\n",
    "    W = np.zeros((n,n), dtype=float)\n",
    "    # identical neighbor selection and weights\n",
    "    for i in range(n):\n",
    "        row = dist_mat[i].copy()\n",
    "        knn_idx = np.argsort(row, kind=\"stable\")[:k]      # same (default quicksort) behavior\n",
    "        thr = row[knn_idx[-1]]\n",
    "        if thr > 0:\n",
    "            W[i, knn_idx] = 1.0 - (dist_mat[i, knn_idx] / thr)\n",
    "\n",
    "    W_sym = (W + W.T) / 2.0\n",
    "    row_sums = W_sym.sum(axis=1, keepdims=True)\n",
    "    nz = row_sums[:,0] > 0\n",
    "    W_sym[nz] /= row_sums[nz]\n",
    "    return W_sym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dde41ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Appendix-B forward selection ===\n",
    "def forward_select_esf(\n",
    "    eig_for_valid: np.ndarray,        # (n_valid, m_eigs)\n",
    "    ln_scal_vals: np.ndarray,      # (n_valid,)\n",
    "    ln_factor_vals: np.ndarray,       # (n_valid,)\n",
    "    W_lps_sub,                        # PySAL weights for valid rows (full2W)\n",
    "    alpha: float = 0.05,\n",
    "    permutations: int = 999,          # Moran permutations; keep 999 for parity\n",
    "    max_add: int = 100,\n",
    "    tol_delta_I: float = 1e-6,\n",
    "    seed: int = 42 \n",
    "):\n",
    "    \"\"\"\n",
    "    Appendix B-style greedy forward selection minimizing Moran's I on residuals.\n",
    "    Guards against None/constant/NaN eigenvectors and singular fits.\n",
    "    Stops when p >= alpha, or Î”I is tiny, or max_add reached.\n",
    "    Returns: (best_model, best_resid, selected_idx)\n",
    "    \"\"\"\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    n_valid, m_eigs = eig_for_valid.shape\n",
    "    selected_idx = []\n",
    "\n",
    "    # Baseline\n",
    "    Xb = sm.add_constant(ln_scal_vals)\n",
    "    base = sm.OLS(ln_factor_vals, Xb).fit()\n",
    "    resid = base.resid\n",
    "    MI = Moran(resid, W_lps_sub, permutations=permutations)\n",
    "    if (MI.p_sim >= alpha) or (m_eigs == 0):\n",
    "        return base, resid, selected_idx\n",
    "\n",
    "    remaining = list(range(m_eigs))\n",
    "    best_model = base\n",
    "    best_resid = resid\n",
    "    last_I = MI.I\n",
    "\n",
    "    # Step 1\n",
    "    best = {\"I\": np.inf, \"p\": None, \"j\": None, \"model\": None, \"resid\": None}\n",
    "    for j in remaining:\n",
    "        xj = eig_for_valid[:, j]\n",
    "        if not np.all(np.isfinite(xj)) or np.nanstd(xj) == 0:\n",
    "            continue\n",
    "        X = sm.add_constant(np.column_stack([ln_scal_vals, xj]))\n",
    "        try:\n",
    "            m = sm.OLS(ln_factor_vals, X).fit()\n",
    "            r = m.resid\n",
    "            Mi = Moran(r, W_lps_sub, permutations=permutations)\n",
    "        except Exception:\n",
    "            continue\n",
    "        if (Mi.I < best[\"I\"]) or (np.isclose(Mi.I, best[\"I\"]) and (best[\"p\"] is None or Mi.p_sim > best[\"p\"])):\n",
    "            best.update({\"I\": Mi.I, \"p\": Mi.p_sim, \"j\": j, \"model\": m, \"resid\": r})\n",
    "\n",
    "    if best[\"j\"] is None:\n",
    "        return base, resid, selected_idx\n",
    "\n",
    "    selected_idx.append(best[\"j\"])\n",
    "    if best[\"j\"] in remaining:\n",
    "        remaining.remove(best[\"j\"])\n",
    "    best_model = best[\"model\"]\n",
    "    best_resid = best[\"resid\"]\n",
    "    if best[\"p\"] is not None and best[\"p\"] >= alpha:\n",
    "        return best_model, best_resid, selected_idx\n",
    "    \n",
    "\n",
    "    # Step 2+\n",
    "    adds = 1\n",
    "    while remaining and adds < max_add:\n",
    "        cand = {\"I\": np.inf, \"p\": None, \"j\": None, \"model\": None, \"resid\": None}\n",
    "        for j in remaining:\n",
    "            X_eigs = eig_for_valid[:, selected_idx + [j]]\n",
    "            if not np.all(np.isfinite(X_eigs[:, -1])) or np.nanstd(X_eigs[:, -1]) == 0:\n",
    "                continue\n",
    "            X = sm.add_constant(np.column_stack([ln_scal_vals, X_eigs]))\n",
    "            try:\n",
    "                m = sm.OLS(ln_factor_vals, X).fit()\n",
    "                r = m.resid\n",
    "                Mi = Moran(r, W_lps_sub, permutations=permutations)\n",
    "            except Exception:\n",
    "                continue\n",
    "            if (Mi.I < cand[\"I\"]) or (np.isclose(Mi.I, cand[\"I\"]) and (cand[\"p\"] is None or Mi.p_sim > cand[\"p\"])):\n",
    "                cand.update({\"I\": Mi.I, \"p\": Mi.p_sim, \"j\": j, \"model\": m, \"resid\": r})\n",
    "\n",
    "        if cand[\"j\"] is None:\n",
    "            break\n",
    "\n",
    "        # early stop if I barely improves\n",
    "        if (last_I - cand[\"I\"]) < tol_delta_I:\n",
    "            break\n",
    "\n",
    "        selected_idx.append(cand[\"j\"])\n",
    "        if cand[\"j\"] in remaining:\n",
    "            remaining.remove(cand[\"j\"])\n",
    "        best_model = cand[\"model\"]\n",
    "        best_resid = cand[\"resid\"]\n",
    "        last_I = cand[\"I\"]\n",
    "        adds += 1\n",
    "        if cand[\"p\"] is not None and cand[\"p\"] >= alpha:\n",
    "            break\n",
    "\n",
    "    return best_model, best_resid, selected_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "446d6518",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import LinearRegression, LassoCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "def _kfold_rmse(X: np.ndarray, y: np.ndarray, folds: int, seed: int) -> float:\n",
    "    \"\"\"K-fold CV RMSE for linear regression with intercept assumed in X.\"\"\"\n",
    "    kf = KFold(n_splits=folds, shuffle=True, random_state=seed)\n",
    "    rmses = []\n",
    "    for tr, te in kf.split(X):\n",
    "        lr = LinearRegression(fit_intercept=False)  # intercept is in X\n",
    "        lr.fit(X[tr], y[tr])\n",
    "        yhat = lr.predict(X[te])\n",
    "        rmses.append(np.sqrt(mean_squared_error(y[te], yhat)))\n",
    "    return float(np.mean(rmses))\n",
    "\n",
    "def _aicc(aic: float, n: int, p: int) -> float:\n",
    "    \"\"\"Small-sample corrected AIC.\"\"\"\n",
    "    return aic + (2 * p * (p + 1)) / (n - p - 1) if (n - p - 1) > 0 else np.inf\n",
    "\n",
    "\n",
    "def calculate_FsAMIs(\n",
    "    df: pd.DataFrame,\n",
    "    factor_columns,\n",
    "    population_column: str,\n",
    "    cbsa_column: str = \"cbsacode\",\n",
    "    alpha: float = 0.05,\n",
    "    moran_permutations: int = 999,\n",
    "    k_values = (7, 8, 10, 12, 15, 18, 22, 26, 30),\n",
    "    seed: int = 42,\n",
    "    cv_folds: int = 5,                 # NEW: folds for CV-RMSE / LASSO\n",
    "    compute_lasso_diag: bool = True    # NEW: toggle LASSO residual diagnostic\n",
    "):\n",
    "    np.random.seed(seed)\n",
    "    n_all = len(df)\n",
    "    print(\"Merged data rows:\", n_all)\n",
    "    if n_all == 0:\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    # --- numeric copy ---\n",
    "    df_num = df.copy()\n",
    "    for col in [population_column, *factor_columns, \"lon\", \"lat\"]:\n",
    "        if col in df_num.columns:\n",
    "            df_num[col] = pd.to_numeric(df_num[col], errors=\"coerce\")\n",
    "\n",
    "    coords_all = df_num[[\"lon\", \"lat\"]].to_numpy()\n",
    "\n",
    "    # --- precompute KNN weights + eigenvectors cache ---\n",
    "    k_cache = {}\n",
    "    for k in k_values:\n",
    "        W_sym_k = construct_knn_weights(coords_all, k=k)\n",
    "        H = np.eye(n_all) - np.ones((n_all, n_all)) / n_all\n",
    "        Omega = H @ W_sym_k @ H\n",
    "        evals, evecs = np.linalg.eigh(Omega)\n",
    "        pos = evals > 1e-12\n",
    "        evals_pos = evals[pos]\n",
    "        evecs_pos = evecs[:, pos]\n",
    "        order = np.argsort(evals_pos)[::-1]\n",
    "        evals_pos = evals_pos[order]\n",
    "        evecs_pos = evecs_pos[:, order]\n",
    "        k_cache[k] = {\"W_sym\": W_sym_k, \"evecs\": evecs_pos, \"evals\": evals_pos}\n",
    "\n",
    "    ln_pop_all = np.log(df_num[population_column]).astype(float)\n",
    "    all_rows = []\n",
    "\n",
    "    # === per-factor loop ===\n",
    "    for factor in factor_columns:\n",
    "        fac_vals = df_num[factor]\n",
    "        pop_vals = df_num[population_column]\n",
    "\n",
    "        coord_ok = (\n",
    "            df_num[\"lon\"].notna() & df_num[\"lat\"].notna() &\n",
    "            np.isfinite(df_num[\"lon\"].to_numpy()) &\n",
    "            np.isfinite(df_num[\"lat\"].to_numpy())\n",
    "        )\n",
    "        valid_mask = (\n",
    "            fac_vals.notna() & pop_vals.notna() &\n",
    "            (fac_vals > 0) & (pop_vals > 0) &\n",
    "            np.isfinite(fac_vals.to_numpy()) &\n",
    "            np.isfinite(pop_vals.to_numpy()) &\n",
    "            coord_ok\n",
    "        )\n",
    "        if not valid_mask.any():\n",
    "            print(f\"[Skip] No valid data for {factor}\")\n",
    "            continue\n",
    "\n",
    "        idx_valid = np.where(valid_mask)[0]\n",
    "        ln_factor = np.log(fac_vals.loc[valid_mask].to_numpy())\n",
    "        ln_pop    = ln_pop_all[valid_mask.to_numpy()]\n",
    "        cbsa_vals = df_num.loc[valid_mask, cbsa_column].to_numpy()\n",
    "        n = ln_factor.shape[0]\n",
    "\n",
    "        evals_k = []\n",
    "\n",
    "        # --- per-k loop ---\n",
    "        for k in k_values:\n",
    "            cache = k_cache[k]\n",
    "            W_sub = cache[\"W_sym\"][idx_valid][:, idx_valid]\n",
    "            W_lps_sub = full2W(W_sub);  W_lps_sub.transform = 'r'\n",
    "\n",
    "            # baseline: y ~ 1 + ln_pop\n",
    "            Xb = sm.add_constant(ln_pop)\n",
    "            model_b = sm.OLS(ln_factor, Xb).fit()\n",
    "            resid_b = model_b.resid\n",
    "            MI_b = Moran(resid_b, W_lps_sub, permutations=moran_permutations)\n",
    "            b_I, b_p = MI_b.I, MI_b.p_sim\n",
    "\n",
    "            # forward-select ESF if needed\n",
    "            eig_for_valid = cache[\"evecs\"][idx_valid, :]\n",
    "            best_model = model_b\n",
    "            best_resid = resid_b\n",
    "            sel_idx = []\n",
    "\n",
    "            if b_p < alpha:\n",
    "                best_model, best_resid, sel_idx = forward_select_esf(\n",
    "                    eig_for_valid=eig_for_valid,\n",
    "                    ln_scal_vals=ln_pop,\n",
    "                    ln_factor_vals=ln_factor,\n",
    "                    W_lps_sub=W_lps_sub,\n",
    "                    alpha=alpha,\n",
    "                    permutations=moran_permutations,\n",
    "                )\n",
    "\n",
    "            selected_m = len(sel_idx)\n",
    "\n",
    "            # final Moran on ESF residuals\n",
    "            MI_f = Moran(best_resid, W_lps_sub, permutations=moran_permutations)\n",
    "            f_I, f_p = MI_f.I, MI_f.p_sim\n",
    "\n",
    "            # --- FINAL MODEL METRICS (this is what you asked for) ---\n",
    "            aic  = best_model.aic\n",
    "            bic  = best_model.bic\n",
    "            p    = len(best_model.params)  # intercept + ln_pop + eigs\n",
    "            aicc = _aicc(aic, n=n, p=p)\n",
    "\n",
    "            # CV-RMSE for the final model (use the actual selected eigs)\n",
    "            # Build design matrix with intercept explicitly (match statsmodels fit)\n",
    "            if selected_m == 0:\n",
    "                X_final = np.column_stack([np.ones(n), ln_pop])\n",
    "            else:\n",
    "                X_final = np.column_stack([np.ones(n), ln_pop, eig_for_valid[:, sel_idx]])\n",
    "            cv_rmse_final = _kfold_rmse(X_final, ln_factor, folds=cv_folds, seed=seed)\n",
    "\n",
    "            # LASSO residual diagnostic on UNUSED eigs (optional)\n",
    "            lasso_R2_unused = None\n",
    "            lasso_n_eigs = None\n",
    "            if compute_lasso_diag:\n",
    "                all_cols = np.arange(eig_for_valid.shape[1])\n",
    "                unused = np.setdiff1d(all_cols, np.asarray(sel_idx, dtype=int))\n",
    "                if unused.size > 0:\n",
    "                    E_unused = eig_for_valid[:, unused]\n",
    "                    pipe = make_pipeline(\n",
    "                        StandardScaler(with_mean=True, with_std=True),\n",
    "                        LassoCV(cv=cv_folds, random_state=seed, max_iter=20000)\n",
    "                    )\n",
    "                    pipe.fit(E_unused, best_resid)\n",
    "                    resid_hat = pipe.predict(E_unused)\n",
    "                    # R^2 on the whole set using refit alpha_ (diagnostic, not CV R^2)\n",
    "                    lasso_R2_unused = float(1.0 - np.var(best_resid - resid_hat) / np.var(best_resid))\n",
    "                    # how many unused eigs selected by LASSO\n",
    "                    coef = pipe.named_steps[\"lassocv\"].coef_\n",
    "                    lasso_n_eigs = int(np.sum(np.abs(coef) > 1e-8))\n",
    "                else:\n",
    "                    lasso_R2_unused = 0.0\n",
    "                    lasso_n_eigs = 0\n",
    "\n",
    "            beta = best_model.params[1]\n",
    "            pval = best_model.pvalues[1]\n",
    "            ci_low, ci_up = best_model.conf_int(alpha=0.05)[1]\n",
    "\n",
    "            # payload to store; we DO NOT select best k here\n",
    "            evals_k.append({\n",
    "                \"k\": k,\n",
    "                # Moran diagnostics\n",
    "                \"final_p\": f_p, \"final_I\": f_I,\n",
    "                \"baseline_p\": b_p, \"baseline_I\": b_I,\n",
    "                # final model metrics\n",
    "                \"aic\": aic, \"bic\": bic, \"aicc\": aicc,\n",
    "                \"cv_rmse_final\": cv_rmse_final,\n",
    "                \"lasso_R2_unused\": lasso_R2_unused,\n",
    "                \"lasso_n_eigs_unused\": lasso_n_eigs,\n",
    "                # params\n",
    "                \"selected_m_eigs\": selected_m,\n",
    "                \"beta\": beta, \"pval\": pval, \"ci_low\": ci_low, \"ci_up\": ci_up,\n",
    "                # payload for rows\n",
    "                \"resid\": best_resid, \"cbsa_vals\": cbsa_vals\n",
    "            })\n",
    "\n",
    "        # --- write out rows for every k (no best-k flags) ---\n",
    "        for d in evals_k:\n",
    "            resid = d[\"resid\"]\n",
    "            for i_local, cval in enumerate(d[\"cbsa_vals\"]):\n",
    "                all_rows.append({\n",
    "                    cbsa_column: cval,\n",
    "                    \"factor\": factor,\n",
    "                    \"k\": d[\"k\"],\n",
    "                    # Moran\n",
    "                    \"baseline_moran_value\": d[\"baseline_I\"],\n",
    "                    \"baseline_moran_p\": d[\"baseline_p\"],\n",
    "                    \"final_moran_value\": d[\"final_I\"],\n",
    "                    \"final_moran_p\": d[\"final_p\"],\n",
    "                    # ESF details\n",
    "                    \"selected_m_eigs\": d[\"selected_m_eigs\"],\n",
    "                    \"FsAMI\": resid[i_local],\n",
    "                    \"beta\": d[\"beta\"],\n",
    "                    \"p_value\": d[\"pval\"],\n",
    "                    \"CI_lower\": d[\"ci_low\"],\n",
    "                    \"CI_upper\": d[\"ci_up\"],\n",
    "                    # --- final model metrics you want ---\n",
    "                    \"AIC\": d[\"aic\"],\n",
    "                    \"BIC\": d[\"bic\"],\n",
    "                    \"AICc\": d[\"aicc\"],\n",
    "                    \"CV_RMSE_final\": d[\"cv_rmse_final\"],\n",
    "                    \"LASSO_R2_unused\": d[\"lasso_R2_unused\"],\n",
    "                    \"LASSO_n_eigs_unused\": d[\"lasso_n_eigs_unused\"]\n",
    "                })\n",
    "\n",
    "    return pd.DataFrame(all_rows)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bf7a3e69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['cbsacode', 'TotalPopulation', 'BINGE', 'CSMOKING', 'DEPRESSION',\n",
       "       'DIABETES', 'LPA', 'OBESITY', 'adult_smoking', 'adult_obesity',\n",
       "       'excessive_drinking', 'diabetes_prevalence', 'some_college',\n",
       "       'unemployment', 'children_single_parent', 'mental_health_providers',\n",
       "       'median_household_income', 'driving_alone_to_work', 'sti', 'FFR20',\n",
       "       'gdp', 'coverage_50', 'coverage_60', 'coverage_70', 'coverage_80',\n",
       "       'coverage_90', 'noise50n', 'noise60n', 'noise70n', 'noise80n',\n",
       "       'noise90n', 'CANCER', 'VISION', 'MOBILITY', 'life_expectancy',\n",
       "       'SELFCARE', 'DISABILITY', 'Park_Area_Acres', 'road_network_total',\n",
       "       'auto_net_total', 'multimodal_net_total', 'pedestrian_net_total',\n",
       "       'street_intersection_total', 'auto_intersections_total',\n",
       "       'multimodal_3leg_intersections_total',\n",
       "       'multimodal_4leg_intersections_total',\n",
       "       'pedestrian_3leg_intersections_total',\n",
       "       'pedestrian_4leg_intersections_total', 'Ac_Land', 'ALAND_acres', 'lon',\n",
       "       'lat'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdd207a8-cf3c-44da-b18c-7f78aa8ce3ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=11)]: Using backend LokyBackend with 11 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged data rows: 875\n",
      "Merged data rows: 875\n",
      "Merged data rows: 875\n",
      "Merged data rows: 875\n",
      "Merged data rows: 875\n",
      "Merged data rows: 875\n",
      "Merged data rows: 875\n",
      "Merged data rows:Merged data rows:  875875\n",
      "\n",
      "Merged data rows: 875\n",
      "Merged data rows: 875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=11)]: Done   2 out of  11 | elapsed: 98.8min remaining: 444.5min\n",
      "[Parallel(n_jobs=11)]: Done  11 out of  11 | elapsed: 125.3min finished\n"
     ]
    }
   ],
   "source": [
    "# First, add these imports at the top of your notebook\n",
    "from joblib import Parallel, delayed\n",
    "import os\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Set master random seed\n",
    "    MASTER_SEED = 42\n",
    "    np.random.seed(MASTER_SEED)\n",
    "    \n",
    "    # Set number of CPU cores to use\n",
    "    n_jobs = max(1, os.cpu_count() - 1)\n",
    "    \n",
    "    factor_columns = ['life_expectancy','road_network_total', 'auto_net_total',\n",
    "       'multimodal_net_total', 'pedestrian_net_total',\n",
    "       'street_intersection_total', 'auto_intersections_total',\n",
    "       'multimodal_3leg_intersections_total',\n",
    "       'multimodal_4leg_intersections_total',\n",
    "       'pedestrian_3leg_intersections_total',\n",
    "       'pedestrian_4leg_intersections_total',]\n",
    "    \n",
    "    def process_factor(factor, seed):\n",
    "        # Each worker gets its own deterministic seed\n",
    "        worker_seed = seed + hash(factor) % 1000000\n",
    "        np.random.seed(worker_seed)\n",
    "        \n",
    "        return calculate_FsAMIs(\n",
    "            df=df,\n",
    "            factor_columns=[factor],\n",
    "            population_column=\"TotalPopulation\",\n",
    "            cbsa_column='cbsacode',\n",
    "            alpha=0.05,\n",
    "            moran_permutations=999,\n",
    "            k_values=(5,6,7,8,9,10,11,12,13,14,15),\n",
    "            seed=worker_seed  # Pass seed to calculate_FsAMIs\n",
    "        )\n",
    "\n",
    "    # Create seeds for each factor\n",
    "    seeds = [MASTER_SEED + i for i in range(len(factor_columns))]\n",
    "    \n",
    "    # Run parallel processing with seeds\n",
    "    results_list = Parallel(n_jobs=n_jobs, verbose=1)(\n",
    "        delayed(process_factor)(factor, seed) \n",
    "        for factor, seed in zip(factor_columns, seeds)\n",
    "    )\n",
    "    \n",
    "    # Combine results\n",
    "    results_df = pd.concat(results_list, ignore_index=True)\n",
    "    \n",
    "    # Save results\n",
    "    results_df.to_csv(f'../00_data/04_output/FsAMIs_pop_allk_allmatrc_add_feature.csv', \n",
    "                      index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "13c739d2-470b-450b-ab7b-4f8e5bda398a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique factors: ['life_expectancy' 'road_network_total' 'auto_net_total'\n",
      " 'multimodal_net_total' 'pedestrian_net_total' 'street_intersection_total'\n",
      " 'auto_intersections_total' 'multimodal_4leg_intersections_total'\n",
      " 'pedestrian_4leg_intersections_total']\n"
     ]
    }
   ],
   "source": [
    "filtered_df = results_df[results_df['final_moran_p'] < 0.05]\n",
    "unique_factors = filtered_df['factor'].unique()\n",
    "print(\"Unique factors:\", unique_factors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a104e19d-f301-4d69-9e6f-de963a74b3c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Factors with ln_pop beta CI crossing 0: []\n"
     ]
    }
   ],
   "source": [
    "factors_crossing_zero = results_df[\n",
    "    (results_df['CI_lower'] < 0) & (results_df['CI_upper'] > 0)\n",
    "]['factor'].unique()\n",
    "\n",
    "print(\"Factors with ln_pop beta CI crossing 0:\", factors_crossing_zero)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "capstone_depression",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
